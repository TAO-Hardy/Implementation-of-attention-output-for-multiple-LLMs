# Implementation-of-attention-output-for-multiple-LLMs
This project is to realize the output of model attention scores in question and answer texts in multiple different large language models. It is thus used to analyze the difference between model attention and human behavior.

.py file is the code for model attention output.

cross_i.txt: This file saved the attention score for the text content from every tokens which from question.

Because there are 7 questions, each folder contains 7 txt files.
